<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <title>aiohttp ile 1 milyon asenkron istek yapmak (çeviri)</title>
    <link href='https://fonts.googleapis.com/css?family=Pacifico' rel='stylesheet' type='text/css' async> 
    <style>
    *{margin:0;padding:0;}
    body{text-align: center;background:#9bd6b8;color: #505664;}
    #blog{width: 60%;margin:0 auto;}
    #blog p{margin-top: 1em;}
    h1{font-size: 3em;font-family: 'Pacifico',cursive;font-weight: 400;margin-top:7%;}
    h2{font-size: 2em;font-family: 'Pacifico',cursive;font-weight: 400;margin-top:1%;}
    a{color: #505664;text-decoration:none;}
    ::selection {
      background:#505664;
      color:#9bd6b8;
    }
    ::-moz-selection {
      background:#505664;
      color:#9bd6b8;
    }
    p{
      font-size: 1.1em;
    }

    ul{
      list-style-type: none;
    }

    ul li:hover{
      font-size:1.2em;
      padding-bottom:0.1em;
      -webkit-transition: all 0.4s ease;
      -moz-transition: all 0.4s ease;
      -o-transition: all 0.4s ease;
      -ms-transition: all 0.4s ease;
    }
    footer{
      margin-top: 6em;
    }
    pre{
      text-align: left
    }
    pre{
      text-align: left
    }
    
    </style>
    <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Article",
      "keywords": "tornado, python, background jobs",
      "name": "aiohttp ile 1 milyon asenkron istek yapmak (çeviri)",
      "creator": {
        "name": "Mehmet Köse",
        "url": "http://mehmetkose.github.io",
      }
    }
    </script>
</head>
<body>
  
  <div id="blog">
    <h1>aiohttp ile 1 milyon asenkron istek yapmak (çeviri)</h1>


    <p>
      <strong>
      <small>
        <a href="http://pawelmhm.github.io/asyncio/python/aiohttp/2016/04/22/asyncio-aiohttp.html">
        Kaynak : "Making 1 million requests with python-aiohttp", Paweł Miech, 2016
        </a>
      </small>
      </strong>
    </p>

    <p>Bu yazıda Python aiohttp'nin sınırlarını test etmek ve dakikalık istek performansını kontrol etmek istiyorum. Herkes, asenkron kodun network işlerinde kullanıldığında daha iyi performans gösterdiğini bilir, fakat bu varsayımın tam olarak nasıl ve neden bu kadar iyi olduğunu kontrol etmek hala ilgi çekici. Python aiohttp ile bir milyon istek yaparak bunu kontrol edeceğim. Dakikada kaç istek yapacak? Basit bir script komut ile bunu yapmaya çalıştığımda ne tarz çökme ve hatalar beklemeliyim? Böyle bir yoğunlukta istek yapmaya çalışırken düşünülmesi gereken ana başlıklar nelerdir?</p>

    <h2>Merhaba asyncio/aiohttp</h2>
    
    <p>Async programlama kolay değildir. Kolay değildir çünkü callback'ler kullanır, olayların şartlarını ve olay işleyicilerini düşünmek normal programlamadan çok daha fazla efor gerektirir. Ayrıca bu biraz farklı çünkü asyncio hala nispeten yeni ve bu konuyla alakalı sadece birkaç blog gönderisi ve eğitim var. Konuyla alakalı resmi Python Belgeleri ise çok yoğun anlatımlı ve sadece basit örnekleri içeriyor. <a href="http://stackoverflow.com/questions/tagged/python-asyncio?sort=votes&amp;pageSize=50">Stack Overflow</a> üzerinde ise çok fazla soru yok  (Örneğin "twisted" için 2.5K üzeri soru sorulmuş). <a href="http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html">Burada</a>, <a href="http://www.snarky.ca/how-the-heck-does-async-await-work-in-python-3-5">Şurada</a> ve <a href="http://sahandsaba.com/understanding-asyncio-node-js-python-3-4.html">Şurada</a> asyncio hakkında güzel blog yazıları var hatta belki de <a href="https://community.nitrous.io/tutorials/asynchronous-programming-with-python-3">Şu</a>, ve <a href="https://compiletoi.net/fast-scraping-in-python-with-asyncio/">Şu</a> da eklenmeli.</p>


    <p>İşleri kolaylaştırmak için basit olandan başlayıp basit bir "Hello World" örneği ile GET isteği yapıp tek bir HTTP yanıtını işleyelim. Senkron programlamada sadece şu şekilde yaparsınız;</p>

    <pre><code class="python">
      import requests
      def merhaba()
          return requests.get("http://httpbin.org/get")
      print(merhaba())
    </code></pre>

    <p>Peki bu aiohttp ile nasıl olur?</p>

    <pre><code class="python">
    #!/usr/local/bin/python3.5
    import asyncio
    from aiohttp import ClientSession

    async def merhaba():
        async with ClientSession() as session:
            async with session.get("http://httpbin.org/headers") as response:
                response = await response.read()
                print(response)

    loop = asyncio.get_event_loop()
    loop.run_until_complete(merhaba())
    </code></pre>

    <p>Hmm böyle temel bir görev için çok fazla kod yazmak gerekiyor gibi.. Burada “async def”, “async with”, “await” var. İlk başta karmaşık gibi görünebilir, haydi açıklamaya çalışalım.</p>

    <p><a href="https://www.python.org/dev/peps/pep-0492/#await-expression">async</a> deyimini fonksiyon tanımlarken kullandığımız def deyiminden önce kullanarak ve fonksiyon içerisinde await kullanarak bir fonksiyonu asenkron hale getirirsiniz. Aslında merhaba() işlevi çalışırken iki asenkron operasyon gerçekleşir. Önce asenkron olarak yanıt getirilir, sonra asenkron olarak yanıt gövdesi okunur.</p>

    <p>Aiohttp, istekler yapmak için birincil arabirim olarak ClientSession metodunu önerir. ClientSession iki istek arasındaki çerezleri saklayabilme imkanı verir ve tüm istekler için ortak olan nesneleri tutar (event loop, bağlantı ve diğer şeyler). Session kullanıldıktan sonra kapatılması gerekir ve oturum kapamak bir başka asenkron işlemdir. Bu yüzden async deyimine ihtiyacınız var ve her seferinde session'lar ile uğraşmanızın nedeni bu.</p>

    <p>client session açtıktan sonra bunları istek yapmak üzere kullanabilirsiniz. Burası isteği indiren asenkron operasyonun başladığı yerdir. Client session'ların yanıtı durumunda olduğu gibi açıkca kapatılması gerekir ve bağlam yöneticisi olan <strong>with</strong> her koşulda düzgün kapatılmasını sağlar.</p>

    <p>Programı başlatmak için event loop (olay döngüsü)'nü çalıştırmanız gerekir ve bunu yapmak için asyncio instance'ı yaratmanız ve bu döngünün içine görevi koymanız gerekir. </p>

    <p>Tüm bunlar biraz zor geliyor olabilir fakat anlamaya çalışırken biraz zaman harcamak mantıklı görünüyor.</p>

    <h2>Çoklu url getirmek</h2>

    <p>Şimdi daha ilginç bir şey deneyelim ve birbirini takip eden isteklerle çoklu url getirelim. Senkron (Bildiğimiz normal çalışan) kod aşağıdaki gibi oluyor.</p>

    <pre><code>
    for url in urls:
      print(requests.get(url).text)
    </code></pre>

    <p>Bu kodu yazması ve kullanması çok kolay, fakat Asenkron bu kodar kolay olmayacak. Bu yüzden daha karmaşık bir şeye gerçekten ihtiyacınız olup olmadığını her zaman düşünmelisiniz. Uygulamanız senkron kod ile düzgün çalışıyorsa belki de asenkron kod ile daha karmaşık hale getirmeye gerek olmayabilir. Eğer zahmetli olan yolu seçip Asenkron kod yazmak isterseniz yapmanız gereken şey aşağıda. Bizim merhaba() fonksiyonumuz hala aynı kalacak fakat bizim tüm listeyi görev olarak asyncio Future nesnesi haline getirip çalıştırılmak üzere loop'a vermemiz gerekiyor.</p>

    <pre><code>
      loop = asyncio.get_event_loop()
      tasks = []
      
      url = "http://httpbin.org/get"
      for i in range(5):
          task = asyncio.ensure_future(hello(url.format(i)))
          tasks.append(task)
      loop.run_until_complete(asyncio.wait(tasks))
    </code></pre>

    <p>Şimdi diyelim ki tüm yanıtları toplamak ve onlara bazı ön işlemler uygulamak istiyoruz. Şu an biz hiçbir yerde yanıt gövdesini tutmuyoruz, sadece ekrana basıyoruz. Haydi yanıt döndürelim ve en sonda hepsini basalım. </p>

    <p>Yanıtları bir gruba toparlamak için muhtemelen aşağıdaki gibi bir şey yapmak gerekir.</p>

    <pre><code>
      #!/usr/local/bin/python3.5
      import asyncio
      from aiohttp import ClientSession

      async def fetch(url):
          async with ClientSession() as session:
              async with session.get(url) as response:
                  return await response.read()

      async def run(loop,  r):
          url = "http://httpbin.org/get"
          tasks = []
          for i in range(r):
              task = asyncio.ensure_future(fetch(url.format(i)))
              tasks.append(task)

          responses = await asyncio.gather(*tasks)
          print_responses(responses)

      def print_responses(result):
          print(result)

      loop = asyncio.get_event_loop()
      future = asyncio.ensure_future(run(loop, 4))
      loop.run_until_complete(future)
    </code></pre>

    <p><a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.gather">asyncio.gather(), Future nesnelerini bir yerde toplar ve hepsi bitinceye kadar bekler.</a></p>


    <!-- <h2>Ortak Yapılan Hatalar</h2>

    <p></p> -->


    

  </div>

    <footer>
    <small><a href="https://mehmetkose.github.io">2016</a></small> <br />
    <small><a href="https://mehmetkose.github.io">mehmet köse</a></small>
  </footer>
  
<script src="https://highlightjs.org/static/highlight.pack.js"></script>
</body>
</html>
